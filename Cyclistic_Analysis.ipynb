{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8e35ed-56c1-4fc4-bf52-f39a9e186ead",
   "metadata": {},
   "source": [
    "<font size=\"6\">Project Name</font>\n",
    "<br>\n",
    "<font size=\"4\">Project Description. </font>\n",
    "<br>\n",
    "<br>\n",
    "<font size=\"4\">Business Tasks:</font>\n",
    "<font size=\"3\">\n",
    "1. Business Task 1\n",
    "1. Business Task 2\n",
    "1. Business Task 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7defe5d-8533-4174-ae6a-a9588ed033b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf0127-d326-4527-a8d6-ade256933120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c42bc1-f613-4361-a899-10df401b988f",
   "metadata": {},
   "source": [
    "<font size=\"6\">Data Preparation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee9dd8",
   "metadata": {},
   "source": [
    "<font size=\"3\">Convert excel sheet(s) or CSV(s) to SQL tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a196bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your XLSX files\n",
    "xlsx_directory = '/Users/leahbowers/Portfolio/[Project Folder]/'\n",
    "\n",
    "# SQLite database file\n",
    "db_file = 'project_name.db'\n",
    "\n",
    "# Create a SQLite database connection\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "# Iterate through XLSX files in the directory\n",
    "for excel_file in os.listdir(xlsx_directory):\n",
    "    if excel_file.endswith('.xlsx'):\n",
    "        file_path = os.path.join(xlsx_directory, excel_file)\n",
    "        \n",
    "        # Read the XLSX file into a DataFrame\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Replace spaces and special characters in column names with underscores\n",
    "        df.columns = [c.replace(' ', '_').replace('.', '_').replace('-', '_') for c in df.columns]\n",
    "        \n",
    "        # Determine the table name (use the file name without extension)\n",
    "        table_name = os.path.splitext(excel_file)[0]\n",
    "        \n",
    "        # Write the DataFrame to the SQLite database as a new table\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f934def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your CSV files\n",
    "csv_directory = '/Users/leahbowers/Portfolio/[Project Folder]/'\n",
    "\n",
    "# SQLite database file\n",
    "db_file = 'project_name.db'\n",
    "\n",
    "# Create a SQLite database connection\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "# Iterate through CSV files in the directory\n",
    "for csv_file in os.listdir(csv_directory):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, csv_file)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Replace spaces and special characters in column names with underscores\n",
    "        df.columns = [c.replace(' ', '_').replace('.', '_').replace('-', '_') for c in df.columns]\n",
    "        \n",
    "        # Determine the table name (use the file name without extension)\n",
    "        table_name = os.path.splitext(excel_file)[0]\n",
    "        \n",
    "        # Write the DataFrame to the SQLite database as a new table\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b08b7-421f-42fd-8782-47e66fc16c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Project database\n",
    "%sql sqlite:///project_name.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd901d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that table was converted from csv and pulled into database\n",
    "conn = sqlite3.connect('project_name.db')\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        name \n",
    "    FROM sqlite_master \n",
    "    WHERE type='table';\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfae0bf",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Optional:** Cleanup database by removing unwanted tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799770a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up project database\n",
    "conn = sqlite3.connect('database_name.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "table_name_to_remove = 'unwanted_table_name'\n",
    "\n",
    "drop_table_query = f\"DROP TABLE IF EXISTS {table_name_to_remove};\"\n",
    "cursor.execute(drop_table_query)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd895a4f",
   "metadata": {},
   "source": [
    "<font size=\"6\">Preview Tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623392c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm data types are correct\n",
    "conn = sqlite3.connect('database_name.db')\n",
    "query = \"\"\"\n",
    "    PRAGMA table_info(table_name)\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get preview of project table\n",
    "pd.set_option('display.max_columns',None)\n",
    "table_name = pd.read_csv('/Path/to/CSV/File/file_name.csv', encoding='latin1')\n",
    "table_name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de24c51",
   "metadata": {},
   "source": [
    "<font size=\"6\">Data Cleaning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42aa40a",
   "metadata": {},
   "source": [
    "<font size=\"3\">Find duplicates and missing values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the entire table\n",
    "duplicate_rows = table_name[table_name.duplicated()]\n",
    "if duplicate_rows.empty:\n",
    "    print(\"No duplicate rows found.\")\n",
    "else:\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(duplicate_rows)\n",
    "    \n",
    "# Check for missing values in the entire table\n",
    "nan_values = table_name.isna().sum()\n",
    "if nan_values.sum() == 0:\n",
    "    print(\"No missing values found.\")\n",
    "else:\n",
    "    print(\"NaN (Missing Values) Count:\")\n",
    "    print(nan_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017827f7",
   "metadata": {},
   "source": [
    "<font size=\"3\">Remove duplicate rows and replace missing values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are duplicates, remove duplicate rows based on all columns\n",
    "table_name_clean = table_name.drop_duplicates()\n",
    "\n",
    "# If no duplicates, start here. Replace blank cells with 0 in specific columns. \n",
    "table_name_clean = table_name[\"column1\"].fillna(0, inplace=True)\n",
    "\n",
    "# Replace blank cells with \"not given\" in specific column.\n",
    "table_name_clean = table_name[\"column2\"].fillna(\"not given\", inplace=True)\n",
    "\n",
    "# Check for missing values in the entire table\n",
    "nan_values = table_name_clean.isna().sum()\n",
    "if nan_values.sum() == 0:\n",
    "    print(\"No missing values found.\")\n",
    "else:\n",
    "    print(\"NaN (Missing Values) Count:\")\n",
    "    print(nan_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8848c",
   "metadata": {},
   "source": [
    "<font size=\"3\">Remove whitespace</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in table_name.columns:\n",
    "    # Check if the column contains strings (object dtype)\n",
    "    if table_name[column].dtype == 'object':\n",
    "        # Strip leading and trailing whitespace from string values\n",
    "        table_name[column] = table_name[column].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b8699",
   "metadata": {},
   "source": [
    "<font size=\"3\">Rename Columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f580417",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_clean.rename(columns={\"column_name\":\"renamed_column\",\"column_name2\": \"renamed_column2\"}, inplace=True)\n",
    "print(table_name_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f371c",
   "metadata": {},
   "source": [
    "<font size=\"3\">Concatenate columns and convert to different data type</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f22a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple columns into a single string column with delimiter\n",
    "table_name_clean['new_column'] = table_name_clean['column1'].astype(str) + '[delimiter]' + table_name['column2'].astype(str)\n",
    "\n",
    "# Convert the concatenated column to different data type format\n",
    "table_name_clean['new_column'] = pd.to_[datatype](table_name_clean['new_colun'], format='%m/%d/%Y')\n",
    "\n",
    "# Drop the individual component columns if needed\n",
    "table_name_clean.drop(columns=['column1', 'column2'], inplace=True)\n",
    "\n",
    "table_name_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed5b26",
   "metadata": {},
   "source": [
    "<font size=\"3\">Apply proper case</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the title case transformation to column1\n",
    "table_name_clean['column1'] = table_name_clean['column1'].str.title()\n",
    "\n",
    "table_name_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20929620",
   "metadata": {},
   "source": [
    "<font size=\"3\">Split column with multiple parts and reorder</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8390e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum number of parts in the column with multiple parts. Add 1 to account for columns with only 1 part\n",
    "max_parts = table_name_clean['column with mult. parts'].str.count(',') + 1 \n",
    "\n",
    "# Determine the maximum number of parts\n",
    "max_n = max_parts.max()\n",
    "\n",
    "# Split the new_column by comma and expand it into separate columns\n",
    "split_columns = [f'new_column{i}' for i in range(1, max_n + 1)]\n",
    "split_artists = table_name_clean['new_column'].str.split(',', expand=True, n=max_n)\n",
    "split_artists.columns = split_columns\n",
    "\n",
    "# Drop the original column if you don't need it anymore\n",
    "table_name_clean.drop(columns=['column with mult. parts'], inplace=True)\n",
    "\n",
    "print(table_name_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248127b",
   "metadata": {},
   "source": [
    "<font size=\"3\">Reorder columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List new column names in desired order\n",
    "column_order = ['column1', 'column2', 'column3']\n",
    "table_name_clean = table_name_clean[column_order]\n",
    "\n",
    "table_name_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3121703",
   "metadata": {},
   "source": [
    "<font size=\"3\">Remove non-character symbols from strings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65616d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove symbols from column1\n",
    "table_name_clean['column1'] = table_name_clean['column1'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "table_name_clean.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f047fc7",
   "metadata": {},
   "source": [
    "<font size=\"3\">Print cleaned table to CSV</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc851b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the CSV file\n",
    "csv_file_path = '/Path/to/CSV/File/table_name_clean.csv'\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "table_name_clean.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Print a message to confirm the file has been saved\n",
    "print(f\"DataFrame saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ec913-dfd4-47c2-8f23-8699c4730358",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb7b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get preview of online_sales table\n",
    "pd.set_option('display.max_columns',None)\n",
    "[var] = pd.read_csv('/Users/leahbowers/Portfolio/[Project Folder]/project_name.csv')\n",
    "var.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicate_rows = var[var.duplicated()]\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "# Check for NaN (missing values)\n",
    "nan_values = var.isna().sum()\n",
    "print(\"\\nNaN (Missing Values) Count:\")\n",
    "print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced10ef7",
   "metadata": {},
   "source": [
    "<font size=\"6\">Question 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2c353",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Question**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244daadb",
   "metadata": {},
   "source": [
    "<font size=\"3\">Answer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total revenue across store\n",
    "conn = sqlite3.connect('project_name.db')\n",
    "query = \"\"\"\n",
    "QUERY;\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('online_sales.db')\n",
    "query = \"\"\"\n",
    "QUERY;\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "\n",
    "month_names = {\n",
    "    '01': 'Jan',\n",
    "    '02': 'Feb',\n",
    "    '03': 'Mar',\n",
    "    '04': 'Apr',\n",
    "    '05': 'May',\n",
    "    '06': 'Jun',\n",
    "    '07': 'Jul',\n",
    "    '08': 'Aug',\n",
    "    '09': 'Sep',\n",
    "    '10': 'Oct',\n",
    "    '11': 'Nov',\n",
    "    '12': 'Dec'\n",
    "}\n",
    "result['month'] = result['month'].map(month_names)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(result['month'], result['total_revenue'], color=['#fe938c', '#edaf97', '#c49792', '#ad91a3'])\n",
    "plt.title('Total Revenue by Month Shows Strongest Earnings in January and Weakest in February', fontsize = 14)\n",
    "plt.xlabel('Month',fontsize = 12)\n",
    "plt.ylabel('Total Revenue',fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sales['browser'].value_counts(normalize=True).plot(\n",
    "    kind='pie',\n",
    "    autopct='%1.1f%%',\n",
    "    ylabel=' ',\n",
    "    shadow=True,\n",
    "    colors=['#fe938c', '#edaf97', '#c49792', '#ad91a3'],\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "ax.set_title('Chrome is the Preferred Browser for Et Femme Shoppers', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8e42f",
   "metadata": {},
   "source": [
    "<font size=\"6\">Question 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ad06d-7dec-45e6-a471-b09f17bfa489",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Question**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e5daa",
   "metadata": {},
   "source": [
    "<font size=\"3\">Answer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21ce5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1a70b44",
   "metadata": {},
   "source": [
    "<font size=\"6\"> Question 3 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62978576-e7fa-4b27-9611-1cfeb76fac52",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Question**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9730b7d",
   "metadata": {},
   "source": [
    "<font size=\"3\">Answer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b115d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f828b1e",
   "metadata": {},
   "source": [
    "<font size=\"6\">Conclusion and Recommendations</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1f546-01ff-4f35-adb2-ada5bee28055",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Description.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ecb67",
   "metadata": {},
   "source": [
    "<font size=\"2\">All data for this project was acquired through Kaggle's Database \"[Database]\"</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
